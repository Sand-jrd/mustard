{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use MUSTARD estimator\n",
    "\n",
    "<font color='purple'>An script version of this notebook is available [here](https://github.com/Sand-jrd/mustard/blob/main/demo.py) </font>\n",
    "\n",
    "1. [Build the estimator](#Build-the-estimator)\n",
    "\n",
    "\n",
    "2. [Use the estimator](#Use-the-estimator)\n",
    "    - [Regularization settings](#Define-the-regularization)\n",
    "    - [Launch estimation](#Start-the-minimization) \n",
    "    \n",
    "    \n",
    "3. [Results](#Results)\n",
    "    - [Outputs](#Results)\n",
    "    - [Residual : Map of noises](#-Residual)\n",
    "    - [Convergence](#-Evolution-of-the-criteria)\n",
    "    \n",
    "\n",
    "<img src=\"./example-data/demo.gif\" alt=\"demo\" width=\"500\" text-align=\"center\"/>\n",
    "\n",
    "## <ins><font color=#1945D6>Build the estimator</font></ins>\n",
    "\n",
    "MUSTARD is object-oriented.\n",
    "The estimator object need the ADI cube <font color='red'>**centred and normalized**</font> and the angle to be build.\n",
    "        \n",
    "First, we import the package we will need\n",
    "(don\"t forget to install mustard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits HDU-0 data successfully loaded. Data shape: (66, 256, 256)\n",
      "Fits HDU-0 data successfully loaded. Data shape: (66,)\n"
     ]
    }
   ],
   "source": [
    "# Mustard estimator\n",
    "from mustard import mustard_estimator\n",
    "\n",
    "# Also, this will help you build the mask fo regularization\n",
    "from mustard.utils import gaussian\n",
    "\n",
    "# Misc\n",
    "from vip_hci.fits import open_fits\n",
    "from vip_hci.preproc import cube_crop_frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the data and build the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ADI cube (1 channel) and the associated angles\n",
    "datadir = \"./example-data/\"\n",
    "\n",
    "science_data = open_fits(datadir+\"cube\")\n",
    "angles = open_fits(datadir+\"angles\")[0]\n",
    "\n",
    "# Note : Don't hestiate to crop the cubes it is time/ressources-consuming\n",
    "science_data = cube_crop_frames(science_data, 256)\n",
    "\n",
    "estimator = mustard_estimator(science_data, angles=angles, coro=10,  pupil=\"edge\", Badframes=None, hid_mask=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation builed the object that represent the estimator. At this point, it only stores information about the dataset.\n",
    "\n",
    "### <ins><font color=#3498DB> Regularization\n",
    "\n",
    "#### <ins><font color=#3498DB> Circular ambiguities\n",
    "\n",
    "State-of-the-art algorithms suffer from a lack of a circularly invariant component in the disk estimate due to their incapacity of distinguishing the disk's flux invariant to the rotation from a static component (i.e., speckle field).\n",
    "In a dataset, both disk and speckle field morphologies contain flux invariant to the rotation. Depending on how aggressively the algorithm will remove the quasi-static contribution from the dataset, more deformation will appear.\n",
    "    \n",
    "We aim to correct for the geometrical biases of standard PSF-subtraction techniques, which generally assign any rotation-invariant flux fully to the reconstructed PSF, by making an assumption on the morphology of the speckle field.\n",
    "    \n",
    "For that purpose, we will defin a Gaussians with a width set to match the spread of the stellar halo. \n",
    "    \n",
    "While fine-tuning of the mask from a dataset to another is expected to improve our results, we rather considered a realistic case scenario of not knowing beforehand the stellar halo profile due to the potential presence of bright disk signals. \\texttt{MUSTARD} is initialized with the mean derotated ADI sequence (as in noADI) in order to assign all ambiguous flux to the disk as first estimate. Hence, this regularization will push out the ambiguous flux that does not belong to the disk accordingly to the shape of the mask. \n",
    "    \n",
    "In addition, we define a smoothness regularization term using the spatial gradient of the estimated circumstellar and stellar signals $d$ and $s$, respectively. It is a common regularization to compensate for noise.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask\n",
    "\n",
    "shape = estimator.model.frame_shape # Get the frame shape here.\n",
    "M = circle(shape, shape[0]//2) + 10*circle(shape, 13) \n",
    "\n",
    "# Configure R2\n",
    "estimator.configR2(Msk=None, mode=\"l1\", penaliz=\"X\", invert=True)\n",
    "\n",
    "# Configure R1\n",
    "estimator.configR1(mode=\"smooth\", p_L=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins><font color=#3498DB> Parameters\n",
    "\n",
    "Finally, MUSTARD required to set few parameters (you can keep defaults) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'w_r'   : 0.15,         # Proportion of Regul over J\n",
    "        'w_r2'   : 0.03,         # Proportion of Regul2 over J\n",
    "        'w_r3'   : 0.001,        # Proportion of Regul2 over J\n",
    "        'w_way'  : (1, 0),       # You‡ can either work with derotated_cube or rotated cube. Or both\n",
    "        'gtol'   : 1e-100,       # Gradient tolerence. Stop the estimation when the mean of gradient will hit the value\n",
    "        'kactiv' : 0,            # Iter before activate regul (i.e when to compute true weight base on w_r proportion)\n",
    "        'estimI' : \"None\",       # Estimate frames flux is highly recommended ! possible value : {\"Frame\",\"L\",\"Both\"}\n",
    "        'weighted_rot' : False,  # Compute weight for each frame according to PA angle separations.\n",
    "        'suffix' : \"test\",       # # Name of your simulation (this is optional)\n",
    "        'maxiter': 13,\n",
    "        'mask_L': (0 , 100),\n",
    "        'init_maxL': True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-`w_r` and `w_r2`, define respectivly the weight of the regularization terms to smooth and to sort circular ambiguity (the last one will be explain later). <font color='red'>**A weight between 10%-5% is recommanded**</font> in order to <ins>let the data attachment terme drive the estimation</ins> to avoid deformations. R2 can be higher if you purposly want to get rid of all circular ambiguities from the disk estimations. \n",
    "\n",
    "-`w_r` define the model definition. **If your signal is corrupted by Gibbs artifact, you can swhitch to reverse mode.** In reverse mode, the speckels map is rotating and it is less likely to cause such problem. You can also try both way at the same time but it takes more time and will not necessarly give better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins><font color=#3498DB> Start the minimization\n",
    "    \n",
    "The demo from \"exemple-data\" usually takes ~4mins.\n",
    "    \n",
    "**TIP :** Click on the ◼︎ icon to stop prematurely the minimization\n",
    "(or ctrl+C if you are using a console). It will quit proprely the iterative loop. Results will be stored/saved/return.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Resolving IP-ADI optimization problem - name : \n",
      " Outputs will be saved ./example-data/\n",
      "Regul R1 : 'smooth' and R2 : 'l1 on X inverted'\n",
      "No deconvolution and with frame weighted based on rotations\n",
      "Relative amplitude of BothX and L will be estimated\n",
      "Regul weight are set to w_r=5.00e-02 and w_r2=1.00e-01, maxiter=60\n",
      "\n",
      "|it |       loss        |        R1        |        R2        |       Rpos       |       total      |\n",
      "| 0 |6.503639e-05 (100%)|0.000000e+00 (0 %)|0.000000e+00 (0 %)|0.000000e+00 (0 %)|6.503639112875e-05|\n"
     ]
    }
   ],
   "source": [
    "L_est, X_est = estimator.estimate(**param, save=datadir, gif=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFO** : The iteration k+1/2 is the step where regularization weights are computed. \n",
    "\n",
    "### <ins><font color=#3498DB>Results\n",
    "\n",
    "The estimator store all the results. It does also provide some method to get relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import percentile\n",
    "\n",
    "plt.figure(\"Results\",figsize=(16,9))\n",
    "plt.subplot(121), plt.imshow(L_est,cmap='jet',vmax=percentile(L_est,99.5))\n",
    "plt.subplot(122), plt.imshow(X_est,cmap='jet',vmax=percentile(L_est,99))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins><font color=#17A67E> Evolution of the criteria\n",
    "This method return the array of the values of the criteria at each iteration. If you set `show=True` or `save=$path$`, it will also plot the convergence curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = estimator.get_evo_convergence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins><font color=#17A67E> Frame weight \n",
    "\n",
    "The frame weight is computed based on the PA angle vector of each frame. Indeed for the sake of the estimation, if the angle between two frame is two small, there is chance that the signal will overllap and it can biais the results.\n",
    "\n",
    "The fuction below return the vector of frame weights.\n",
    "If you set `show=True` or `save=$path$`, it will also plot the weight bars and the PA angle cuve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = estimator.get_rot_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins><font color=#17A67E> Residual\n",
    "\n",
    "This is the noise. If you see some structures that is alright. This map containt every kind of noise - not only white.\n",
    "MUSTARD can distangle noise that have a life time between *( exposure time < lifetime < aquisition-time/2 )*.\n",
    "\n",
    "**Look carefully**, because if you see very clear structes that look like the disk and/or that appear on more that half of the frames it might be a sign that something went wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import percentile\n",
    "from hciplot import plot_cubes\n",
    "\n",
    "residual = estimator.get_residual()\n",
    "lim = percentile(abs(residual),99) # TIP : try without percentile.\n",
    "plot_cubes(residual,cmap=\"jet\",vmax=lim,vmin=-lim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins><font color=#17A67E> Reconstruction\n",
    "\n",
    "This is the reconstruction. It should look like the initial ADI cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = estimator.get_reconstruction()\n",
    "plot_cubes(reconstruction, cmap=\"jet\", vmax=percentile(reconstruction,99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS** : You can generate the mustard gif of your simulation (the one in introcution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.mustard_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be print saved in your datadir. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
